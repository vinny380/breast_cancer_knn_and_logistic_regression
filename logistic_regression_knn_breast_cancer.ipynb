{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOC5ttcpnqkHlwv8kdUKl3w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinny380/breast_cancer_knn_and_logistic_regression/blob/main/logistic_regression_knn_breast_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN From Scratch"
      ],
      "metadata": {
        "id": "PVLPIwU-UKxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data Preprocessing\n",
        "I'll first load the dataset, normalize it, and split it into training and testing sets."
      ],
      "metadata": {
        "id": "8IH6xHwvTPNc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xIi6_HjSOyiO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#loading the dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  #features\n",
        "y = data.target  #target (0 for benign, 1 for malignant)\n",
        "\n",
        "#normaliziing the data\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "#splitting the dataset (70% training, 30% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. KNN Implementation from Scratch\n",
        "Now I'll implement the K-Nearest Neighbors algorithm. I'll manually calculate the Euclidean distance, select the k nearest neighbors, and classify based on the majority vote."
      ],
      "metadata": {
        "id": "iRECuIiHTDii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "    def __init__(self, k: int = 3) -> None:\n",
        "        self.k = k\n",
        "        self.X_train = np.array([])\n",
        "        self.y_train = np.array([])\n",
        "\n",
        "    def fit(self, X_train: np.ndarray, y_train: np.ndarray) -> None:\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def euclidean_distance(self, x1: np.ndarray, x2: np.ndarray) -> float:\n",
        "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "\n",
        "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
        "        predictions = [self._predict(x) for x in X_test]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _predict(self, x: np.ndarray) -> np.int64:\n",
        "        #computing distances between x and all samples in the training set\n",
        "        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]\n",
        "        #sorting by distance and return indices of the first k neighbors\n",
        "        k_indices: np.ndarray = np.argsort(distances)[:self.k]\n",
        "        #extracting the labels of the k nearest neighbor training samples\n",
        "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
        "        #returns the most common class label\n",
        "        return np.bincount(k_nearest_labels).argmax()\n",
        "\n",
        "\n",
        "#instantiating KNN with k=3\n",
        "knn = KNN(k=3)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "#now evaluate the model using accuracy\n",
        "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
        "print(f\"KNN accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l37z5HeO45f",
        "outputId": "f5510e9b-e622-417d-a2ca-f0b741dc4c10"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN accuracy: 95.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Parameter Tuning:\n",
        "To find the optimal value for k, I will experiment with different values and evaluate the accuracy of the model on the test set."
      ],
      "metadata": {
        "id": "NaaQMiJmTXL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_k(X_train: np.ndarray, X_test: np.ndarray, y_train: np.ndarray, y_test: np.ndarray) -> int:\n",
        "    accuracies = []\n",
        "    k_values = range(1, 20)\n",
        "\n",
        "    for k in k_values:\n",
        "        knn = KNN(k=k)\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_test)\n",
        "        accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
        "        accuracies.append(accuracy)\n",
        "        print(f\"Accuracy for k={k}: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    optimal_k = k_values[np.argmax(accuracies)]\n",
        "    print(f\"Optimal k: {optimal_k} with accuracy {max(accuracies) * 100:.2f}%\")\n",
        "    return optimal_k\n",
        "\n",
        "# Find the optimal value for k\n",
        "optimal_k = find_best_k(X_train, X_test, y_train, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1l399n1O5go",
        "outputId": "46fbdd5a-51dd-4b3d-ff44-e469c2759f2f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for k=1: 95.32%\n",
            "Accuracy for k=2: 95.32%\n",
            "Accuracy for k=3: 95.91%\n",
            "Accuracy for k=4: 95.91%\n",
            "Accuracy for k=5: 95.91%\n",
            "Accuracy for k=6: 95.91%\n",
            "Accuracy for k=7: 95.91%\n",
            "Accuracy for k=8: 96.49%\n",
            "Accuracy for k=9: 97.08%\n",
            "Accuracy for k=10: 97.08%\n",
            "Accuracy for k=11: 95.91%\n",
            "Accuracy for k=12: 97.08%\n",
            "Accuracy for k=13: 95.91%\n",
            "Accuracy for k=14: 96.49%\n",
            "Accuracy for k=15: 95.32%\n",
            "Accuracy for k=16: 96.49%\n",
            "Accuracy for k=17: 95.32%\n",
            "Accuracy for k=18: 95.32%\n",
            "Accuracy for k=19: 95.32%\n",
            "Optimal k: 9 with accuracy 97.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metrics:\n",
        "Now I'll compute additional evaluation metrics like precision, recall, and F1-score. Since no model training is involved here, I'll use `scikit-learn`"
      ],
      "metadata": {
        "id": "w_TWnaabTiL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLwWdlt3PBhX",
        "outputId": "88e40837-fb6f-4e86-e0c9-b2e98358c87b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94        63\n",
            "           1       0.96      0.97      0.97       108\n",
            "\n",
            "    accuracy                           0.96       171\n",
            "   macro avg       0.96      0.95      0.96       171\n",
            "weighted avg       0.96      0.96      0.96       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression With `Scikit-Learn`"
      ],
      "metadata": {
        "id": "3xS1dCLNUN31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "#creating a Logistic Regression model\n",
        "logreg = LogisticRegression(random_state=42, max_iter=10000)\n",
        "\n",
        "#fitting the model on the training data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "#making predictions on the test data\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "\n",
        "#finally, evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred_logreg)\n",
        "precision = precision_score(y_test, y_pred_logreg)\n",
        "recall = recall_score(y_test, y_pred_logreg)\n",
        "f1 = f1_score(y_test, y_pred_logreg)\n",
        "\n",
        "print(f\"Logistic Regression Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {precision * 100:.2f}%\")\n",
        "print(f\"Recall: {recall * 100:.2f}%\")\n",
        "print(f\"F1 Score: {f1 * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLgeDhCEUpAP",
        "outputId": "379989ed-9010-48c0-f162-677c576c0a6f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 98.25%\n",
            "Precision: 99.07%\n",
            "Recall: 98.15%\n",
            "F1 Score: 98.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred_logreg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5AjVJLMW9IC",
        "outputId": "54c29fe7-03b5-4d06-b9f9-a5afe956e950"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98        63\n",
            "           1       0.99      0.98      0.99       108\n",
            "\n",
            "    accuracy                           0.98       171\n",
            "   macro avg       0.98      0.98      0.98       171\n",
            "weighted avg       0.98      0.98      0.98       171\n",
            "\n"
          ]
        }
      ]
    }
  ]
}